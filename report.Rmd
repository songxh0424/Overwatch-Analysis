---
title: "Deep Dive into Overwatch Players Career Data"
author: 'Xinghui Song'
date: 'December 11, 2017'
output: 
  pdf_document:
    number_sections: true
header-includes:
   - \usepackage{indentfirst}
   - \usepackage{subfig}
   - \usepackage{graphicx}
   - \usepackage{float}
   - \usepackage{amsmath}
fontsize: 10pt
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = "center", message = FALSE, warning = FALSE, comment = "", fig.pos = "H", cache = FALSE)
library(knitr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(dplyr)
library(tidyr)
library(stringr)
library(ggthemes)
library(grid)
library(scales)
library(lubridate)
source('./functions.R')
load('./data_cleaned.RData')
```

# Motivation

Since its official release back in May 2016, Overwatch has quickly became one of the most popular online multiplayer 
first person shooter video game, garnering over 35 million players in total over the past year. For a online game with such
popularity, a massive amount of data are generated everyday. These data are proved to be invaluable in evaluating the 
balanceness of playable characters and the fairness of matchmaking. 

To give a bit more information on the game, at the moment, there are 26 playable characters (aka. heroes)
in the Overwatch roster. Each competitive game separates players into two teams of six. Players on the same team must pick six
different heroes. After the first 10 "Placement matches", a player is given a skill rating (SR) calculated based on his/her
performance in those matches as well as the match outcomes. After that, every competitive game the player participates will
result in an addition or subtraction to the player's current SR. Due to the nature of this SR system, it is very important
for the game developers to constantly tweak the gameplay design of heroes to ensure that no hero becomes too overpowered or 
underpowered.

The main goal of this project is to analyze the hero usage and game statistics, and how their distributions vary across different
levels (SR, SR tier) of players. More specifically, we will be looking at the data from the following four aspects:

+ Overall distribution of SR and hero/class usage.
+ Compare game stats and hero usage between players in different levels.
+ Does meta heroes performe better than others?
+ Is it possible to predict SR based on overall/average statistics?


# Data Sources

Players' statistics can be found on various website including the [official Overwatch website](https://playoverwatch.com) 
and [overwatchtracker.com](https://overwatchtracker.com).
Datasets used in this project are scraped from these two websites using R package `rvest`. We first scrape players'
battle tags (player id) overwatchtracker [leaderboard](https://overwatchtracker.com/leaderboards/pc/global). Then we use
the battle tags to access each individual player's career statistics page and scrape all relevant tables. The final
output contains information on 16500 players, each having around 200 or so small tables for different heroes and different
group of stats. Take player Wraxu#1747 for example, his career profile can be found at 
https://playoverwatch.com/en-gb/career/pc/us/Wraxu-1747. By simply replacing the battle tag string at the end, we can
scrape every player's data as long as the player participates in the current competitive season. 

On each player's profile page, there are usually up to eight tables under categories "Hero Specific", "Combat", "Assists", 
"Best", "Average", "Match Awards", "Game" and "Miscellaneous" for each hero he/she played. We first bind tables in the same category
but of different heroes into one large table, and then bind tables across all players. So in the end, we have eight large tables
corresponding to the eight categories mentioned above. Each row of those tables has two additional variables to identify which 
player and which hero this row belongs to. The tables are then stored in a list and saved as an RData file. 

Since we are only concerned with competitive games, we restrict the data to the current competitive season, which starts in early
November and ends mid-December. There are over 200 variables with eight tables combined. Some of the variables that we are most
interested in include `SR`, `Games Played`, `Games Won`, `Eliminations`, `Deaths`, `Time Spent on Fire`, `Objective Time`, etc.
All variables are saved as characters during the scraping process, most of which will be converted to numeric or time period type
when analyses are carried out.

# Data Gathering and Processing

## Scraping data from the web

Here we will explain the data gathering process in further details. The first step is to get a decent amount of players' battle
tags to pull data from. The overwatchtracker's leaderboard has an extensive list of players that occupy over 1650 webpages with
exactly 100 players on each page. Additionally, the url of these pages are nicely formatted as
https://overwatchtracker.com/leaderboards/pc/global/CompetitiveRank?page=1&mode=1. This allows us to effortlessly access each
page by simply changing the page number. During this step, we randomly sample 10 players on each page from page 1 to page 1650,
which covers the SR range of 900 to 4800. This gives us the battle tags of 16500 players across different skill levels. 

After getting the battle tags, we plug each one of them into the overwatch career profile url mentioned in last section. At the
top of a player's profile page, there is his current SR and an image of the hero he used the most. Both of those are important
to our analyses so they are stored in a list object corresponding to the player. The main portion of the profile page are a
collection of tables, usually 7 or 8 tables. The default layout of those tables displays aggregated statistics of all heroes.
Statistics of specific heroes can be accessed through a dropdown menu. For each player, we use `rvest` package to scrape all 
tables from both the "all heroes" layout as well as every individual hero layout, and then bind the same table from different
heroes into a single large table with an added column of hero names. So one player's profile page yields up to 8 tables. 

Out of the 16500 players, around 1200 or so have their information misrepresented on overwatchtracker, causing "pages unfound"
error when using their battle tags to make url requests. Addtionally, there are about 3000 players don't have an SR for the 
current season. Fortunately this still leaves us enough data to work with. Now each
player has their statistics stored in eight tables, namely tables "Hero Specific", "Combat", "Assists", "Best", "Average", 
"Match Awards", "Game" and "Miscellaneous". We proceed by binding these tables across all players with a new column indicating
the player's battle tag corresponding to each row. The final products are eight tables under the same names, each having
roughly 190000 rows. Further data cleaning and analyses will be carried out using these tables, stored in a list object
called `dfMerged`. The SR and main hero information scraped earlier are stored in a data frame called `dfPlayer`.

## Data Cleaning

In order to avoid type errors when binding tables, all data fields are read as characters at data gathering step. However,
the majority of the data is meant to be of type numeric or time. We employ packages `stringr` and `lubridate` to convert
those data to desired format. 

Many large integers on the profile pages have commas, which renders the function `as.numeric` powerless in this case. We first
use `str_replace_all` to replace all commas with empty string, and then convert them to numeric values. As for the duration
variables like `Time Spent on Fire` and `Objective Time`, we first make sure that the string has format "hh:mm:ss". If not, 
it can only be of "mm:ss" format and we can fix that by prepend it with "00:". After that, the variable can be converted to
a `Period` object by using function `hms` in package `lubridate`. However `Period` objects appear to be very buggy when put
into a data frame. Therefore we decided to store all time period variables as numeric values indicating the number of seconds
using the `period_2_seconds` function.

Another thing that needs to be cleaned up is typos. The reason this could be an issue is that the typos usually occur in variable
names. For example, variable `Deaths` is misspelled as `Death` in many tables, which causes the same data being split into
two columns and a lot of missing values as a result. Again, we use the `str_replace_all` function with regular expression
to fix the typos and ensure the same data is kept in a single column. 

## Preparing Data Frames for Analyses

Data frame `dfPlayer` plays an important role in each analysis. It contains information on each player's battle tag, SR, SR tier,
main hero, hero difficulty and hero class. Battle tags, SRs main heroes are scraped from the web as mentioned earlier, while the other
variables are manually typed into a table called `dfHero` and then joined with `dfPlayer` by hero names. Because all eight tables
in `dfMerged` have columns `Player` and `hero`, we can join any of them with `dfPlayer` by these two columns as the need arises. 

Additional data manipulation for each particular analysis will be explained in the next section. In this project, we mostly use
packages `dplyr` and `tidyr` to transform data frames into what we need. 

# Analyses and Visualization

## Overall distribution of SR and hero/class usage.

First let's take a look at the distribution of SR by plotting a histogram. Doing this only requires the `dfPlayer` table so no
additional data manipulation needed. Figure 1 is a histogram of SR with an overlaying density curve. We can see that the distribution
of SR closely resembles a normal distribution with mean around 2700. This is a nice distribution for a skill rating system.
A very noticeable trait of this histogram is the spike at 3000. After a closer look at the underlying data reveals that there are
442 players with an SR of exactly 3000. The reason behind this is that players with SR higher than 3000 will receive continual SR penalties if
they don't play at least seven games per week. For SR within the range of 3000 to 4000, it only takes a few days to decay to 3000, at
which point no further penalty is applied. Among the 12147 players in our datasets, only 2799 of them have an SR at 3000 or above. This
means at least one sixth of high level players are severely affected by the SR decay, and that's not counting the ones whose SR are
still decaying but haven't dropped to 3000 just yet.

```{r, fig.cap = 'Histogram of Skill Rating', fig.height = 3.5, fig.width = 5}
## histogram of SR
p = ggplot(dfPlayer, aes(SR)) +
  geom_histogram(aes(y = ..density..), fill = 'lightblue', color = 'white') +
  geom_line(stat = 'density', color = 'magenta') +
  ## ggtitle('Histogram of SR')
p1 = plot_custom(p)
p1
```

Now let's switch our focus to hero usage. The data preparation step for this analysis is somewhat complicated.
We first join the table `dfMerged$Game` with `dfPlayer` by column `Player` to get the SR and SR tier information.
Then join the output with `dfHero` to get hero specific information. After that, we want to group the rows by
`Player`, rank the play time of each hero in each group and get the percentage of time a player spent on each
hero. Functions `arrange`, `group_by` and `mutate` can achieve this purpose, and function `row_number` proves to
be very useful when it comes to creating a rank column. We name the output table `heroUsage`.

Figure 2 is a bar chart of the number of players that "main" each hero (use one hero the most). Heroes are grouped and colored
by their classes, and the color of hero names indicates hero's difficulty to play (green: easy, yellow: medium, red: hard). 
From the bar charts we can notice a few things about hero usage:
+ The most noticeable thing in the bar chart is that there are far more Mercy mains than any other heroes.  
+ Very few players main defense heroes.
+ Hero difficulty appears to have a slight influence on players' choice of mains. Four out of seven hard heroes
are rarely mained, while most easy heroes are often used. 

Plotting a bar chart of the players' total time spent on each hero gives us an almost identical plot. So we omit the result
to save space for other interesting findings. 

```{r, fig.cap = 'Distribution of Main Heroes', fig.height = 4, fig.width = 6}
## table of hero usage
heroUsage = dfMerged$Game %>% filter(!(hero == 'ALL HEROES')) %>% 
  mutate(hero = hero %>% str_replace('TORBJÖRN', 'TORBJORN') %>%
           str_replace("SOLDIER: 76", 'SOLDIER-76') %>%
           str_replace('D.VA', 'DVA') %>%
           str_replace("LÚCIO", 'LUCIO')) %>%
  left_join(dfPlayer %>% select(btags, SR, Tier) %>% distinct(), by = c('Player' = 'btags')) %>%
  left_join(dfHero, by = 'hero') %>%
  arrange(Player, desc(`Time Played`)) %>%
  group_by(Player) %>% mutate(rank = row_number(), totalTime = sum(`Time Played`)) %>%
  mutate(usePercentage = `Time Played` / totalTime * 100) %>%
  mutate(hero = factor(hero, levels = dfHero$hero),
         class = factor(class, levels = unique(dfHero$class)),
         difficulty = factor(difficulty, levels = c('Easy', 'Medium', 'Hard')))

## bar chart of mained heroes
p = heroUsage %>% filter(rank == 1) %>% group_by(hero) %>%
  summarise(class = unique(class), count = n(), difficulty = unique(difficulty)) %>%
  ggplot(aes(class, count, group = hero, fill = class)) +
  geom_col(position = 'dodge', color = 'white') +
  geom_text(aes(label = hero, color = difficulty), position = position_dodge(0.9),
            angle = 90, size = 1.5, hjust = -0.2, show.legend = FALSE) +
  ylim(c(0, 2500))
plot_custom(p) + scale_color_manual(values = c('mediumseagreen', 'orange', 'red'))

## top and bottom five most played heroes
p = heroUsage %>% filter(rank == 1) %>% group_by(hero) %>%
  summarise(class = unique(class), `Time Played` = sum(`Time Played`), difficulty = unique(difficulty)) %>%
  ggplot(aes(class, `Time Played`, group = hero, fill = class)) +
  geom_col(position = 'dodge', color = 'white') +
  geom_text(aes(label = hero, color = difficulty), position = position_dodge(0.9),
            angle = 90, size = 1.5, hjust = -0.2, show.legend = FALSE) 
plot_custom(p) + scale_color_manual(values = c('mediumseagreen', 'orange', 'red'))
```

Another aspect of hero usage is to look at how players' attribute their total play time with each hero. For example, some
players are good at switching heroes mid match to counter their opponents, while other players can only play one or two heroes
good enough to compete in competitive games. 

## Compare game stats and hero usage between players in different levels.

```{r}
combat = dfMerged$Game %>% filter(hero == 'ALL HEROES', num(`Games Played`) > 50) %>%
  left_join(dfPlayer, by = c('Player' = 'btags')) %>% 
  inner_join(dfMerged$Combat %>% filter(hero == 'ALL HEROES'), by = c('Player')) %>%
  mutate(`Time Played` = hours(`Time Played` %>% str_replace('hours', '') %>% as.numeric()) %>% period_to_seconds())

## hero usage: can compute the log ratio of usage in high level over in low level
```

## Does meta heroes performe better than others?

## Is it possible to predict SR based on overall/average statistics?
